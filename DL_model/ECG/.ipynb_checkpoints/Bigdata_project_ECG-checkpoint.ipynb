{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af33d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f478c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5051118</th>\n",
       "      <th>5051119</th>\n",
       "      <th>5051120</th>\n",
       "      <th>5051121</th>\n",
       "      <th>5051122</th>\n",
       "      <th>5051123</th>\n",
       "      <th>5051124</th>\n",
       "      <th>5051125</th>\n",
       "      <th>5051126</th>\n",
       "      <th>5051127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.635254</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.504395</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.027435</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5051128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5        6        \\\n",
       "0   0.000012  0.002014  0.000856  0.031860  0.000187  0.000015  0.00174   \n",
       "1   0.000012  0.002014  0.001469  0.635254  0.000187  0.000015  0.00174   \n",
       "2   0.000012  0.002014  0.001469  0.382812  0.000191  0.000015  0.00174   \n",
       "3   0.000012  0.002014  0.000061  0.000063  0.000185  0.000015  0.00174   \n",
       "4   0.000012  0.002014  0.001713  0.009918  0.000187  0.000015  0.00174   \n",
       "..       ...       ...       ...       ...       ...       ...      ...   \n",
       "75  0.000012  0.002014  0.019623  0.000155  0.000189  0.000015  0.00174   \n",
       "76  0.000012  0.002014  0.019623  0.000032  0.000191  0.000015  0.00174   \n",
       "77  0.000012  0.002014  0.023529  0.504395  0.000184  0.000015  0.00174   \n",
       "78  0.000012  0.002014  0.023529  0.000500  0.000187  0.000015  0.00174   \n",
       "79  0.000012  0.002014  0.027435  0.000077  0.000191  0.000015  0.00174   \n",
       "\n",
       "     7         8         9        ...  5051118  5051119  5051120  5051121  \\\n",
       "0   0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "1   0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "2   0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "3   0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "4   0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "..       ...       ...       ...  ...      ...      ...      ...      ...   \n",
       "75  0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "76  0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "77  0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "78  0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "79  0.009781  0.131958  0.324463  ...      0.0      0.0      0.0      0.0   \n",
       "\n",
       "    5051122  5051123  5051124  5051125  5051126  5051127  \n",
       "0       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "1       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "2       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "3       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "4       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "..      ...      ...      ...      ...      ...      ...  \n",
       "75      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "76      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "77      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "78      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "79      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[80 rows x 5051128 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECG_data = []\n",
    "\n",
    "for idx in range(1, 81) : #0~89까지 bin file 순회\n",
    "    data_path = os.path.join('ECG_' + str(idx) + '.bin') #file 경로 지정\n",
    "    with open(data_path, \"rb\") as f : # .bin file을 os 함수를 이용하여 rb로 open\n",
    "        data = np.frombuffer(f.read(), dtype=np.float16) # bin file 내용 저장\n",
    "    data = np.append(data, np.array([0]*(5051128 - len(data)))) # 길이가 짧은 것들은 0으로 채우기\n",
    "    ECG_data.append(data) # dataframe을 만들기 위해 data를 ECG_data에 추가\n",
    "\n",
    "    f.close() #읽은 .bin file close\n",
    "    \n",
    "df_col = [i for i in range(0, 5051128)] #dataframe의 column\n",
    "\n",
    "ECG = pd.DataFrame(columns = df_col)\n",
    "\n",
    "for i in range(0, 80) :\n",
    "    ECG.loc[i] = ECG_data[i]\n",
    "ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7fd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG_data = []\n",
    "sub_num = [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 41, 42, 43, 44, 45, 47, 48, 52, 53, 54, 55, 59, 59, 60, 62, 63, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 77, 78]\n",
    "for idx in range(1, 81) : #0~89까지 bin file 순회\n",
    "    if idx in sub_num :\n",
    "        data_path = os.path.join('ECG_' + str(idx) + '.bin') #file 경로 지정\n",
    "        with open(data_path, \"rb\") as f : # .bin file을 os 함수를 이용하여 rb로 open\n",
    "            data = np.frombuffer(f.read(), dtype=np.float16) # bin file 내용 저장\n",
    "    \n",
    "        ECG_data.append(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c542e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ECG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c799dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_mean(arr):\n",
    "    nan_indices = np.isnan(arr)\n",
    "    \n",
    "    if nan_indices[0]:\n",
    "        arr[0] = arr[1]\n",
    "    \n",
    "    if nan_indices[-1]:\n",
    "        arr[-1] = (arr[-2] + arr[-3]) / 2\n",
    "    \n",
    "    for i in range(1, len(arr) - 1):\n",
    "        if nan_indices[i]:\n",
    "            arr[i] = (arr[i-1] + arr[i-2]) / 2\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945dfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(ECG_data)) :\n",
    "    ECG_data[i] = replace_nan_with_mean(ECG_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a022f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(ECG_data)) :\n",
    "    print(np.isnan(ECG_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c82e8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_feel = pd.read_csv('./movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab11bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('./score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c98dff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "      <th>Fourth</th>\n",
       "      <th>Fifth</th>\n",
       "      <th>Sixth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>disgust</td>\n",
       "      <td>fear</td>\n",
       "      <td>sad</td>\n",
       "      <td>happy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>disgust</td>\n",
       "      <td>neutral</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anger</td>\n",
       "      <td>sad</td>\n",
       "      <td>disgust</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>anger</td>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>neutral</td>\n",
       "      <td>sad</td>\n",
       "      <td>happy</td>\n",
       "      <td>fear</td>\n",
       "      <td>disgust</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>anger</td>\n",
       "      <td>sad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fear</td>\n",
       "      <td>happy</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sad</td>\n",
       "      <td>anger</td>\n",
       "      <td>disgust</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>disgust</td>\n",
       "      <td>sad</td>\n",
       "      <td>anger</td>\n",
       "      <td>happy</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>happy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anger</td>\n",
       "      <td>disgust</td>\n",
       "      <td>fear</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      First   Second    Third   Fourth    Fifth    Sixth\n",
       "0   neutral  disgust     fear      sad    happy    anger\n",
       "1     anger  disgust  neutral    happy      sad     fear\n",
       "2     happy  neutral    anger      sad  disgust     fear\n",
       "3   disgust    happy      sad    anger  neutral     fear\n",
       "4   neutral    anger  disgust    happy      sad     fear\n",
       "..      ...      ...      ...      ...      ...      ...\n",
       "84  neutral      sad    happy     fear  disgust    anger\n",
       "85    anger      sad  neutral     fear    happy  disgust\n",
       "86      sad    anger  disgust     fear  neutral    happy\n",
       "87  disgust      sad    anger    happy     fear  neutral\n",
       "88    happy  neutral    anger  disgust     fear      sad\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c95ec94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores.drop([3, 7, 13, 15, 33, 34, 36, 39, 45, 48, 49, 50, 55, 56, 57, 60, 66, 68, 70, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be6c1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3, 1, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid1 = scores[['Video1_neutral', 'Video1_fear', 'Video1_sad', 'Video1_happy', 'Video1_anger', 'Video1_disgust']]\n",
    "vid2 = scores[['Video2_neutral', 'Video2_fear', 'Video2_sad', 'Video2_happy', 'Video2_anger', 'Video2_disgust']]\n",
    "vid3 = scores[['Video3_neutral', 'Video3_fear', 'Video3_sad', 'Video3_happy', 'Video3_anger', 'Video3_disgust']]\n",
    "vid4 = scores[['Video4_neutral', 'Video4_fear', 'Video4_sad', 'Video4_happy', 'Video4_anger', 'Video4_disgust']]\n",
    "vid5 = scores[['Video5_neutral', 'Video5_fear', 'Video5_sad', 'Video5_happy', 'Video5_anger', 'Video5_disgust']]\n",
    "vid6 = scores[['Video6_neutral', 'Video6_fear', 'Video6_sad', 'Video6_happy', 'Video6_anger', 'Video6_disgust']]\n",
    "vid1.loc[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9173301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matsub_num = ['001', '002', '003', '005', '006', '007', '009', '010', '011', '012', '013', '015', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '036', '038', '039', '041', '042', '043', '044', '045', '047', '048', '052', '053', '054', '055', '059', '060', '062', '063', '064', '065', '066', '068', '070', '072', '073', '074', '075', '076', '077', '078']\n",
    "len(matsub_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ceb0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = ['001', '005', '006', '009', '010', '011', '012', '013', '015', '021', '022', '023',\n",
    "             '024', '026', '027', '028', '031', '032', '033', '036', '038', '041', '042', '044',\n",
    "             '045', '047', '053', '054', '055', '060', '062', '063', '064', '066', '070', '072',\n",
    "             '073', '075', '076', '077', '078']\n",
    "test_ids = ['002', '003', '007', '017', '018', '019', '020', '025', '029', '030', '039', '043',\n",
    "            '048', '052', '059', '065', '068', '074']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346b4615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([507, 503, 503, ..., 492, 493, 494], dtype=uint16), array([7, 1, 1, 5, 1, 1], dtype=int64)]\n",
      "[array([445, 444, 446, ..., 453, 454, 453], dtype=uint16), array([7, 1, 1, 5, 1, 1], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "train_label = []\n",
    "test_label = []\n",
    "for num in matsub_num :\n",
    "    mat_path = os.path.join('./ECG_experiment_matfile', num, 'selected_data')\n",
    "    #print(mat_path)\n",
    "    mat_file = scipy.io.loadmat(mat_path)\n",
    "    if num in train_ids :\n",
    "        train_label.append([mat_file['Segment1'][0], vid1.loc[0].values])\n",
    "        train_label.append([mat_file['Segment2'][0], vid2.loc[0].values])\n",
    "        train_label.append([mat_file['Segment3'][0], vid3.loc[0].values])\n",
    "        train_label.append([mat_file['Segment4'][0], vid4.loc[0].values])\n",
    "        train_label.append([mat_file['Segment5'][0], vid5.loc[0].values])\n",
    "        train_label.append([mat_file['Segment6'][0], vid6.loc[0].values])\n",
    "    else :\n",
    "        test_label.append([mat_file['Segment1'][0], vid1.loc[0].values])\n",
    "        test_label.append([mat_file['Segment2'][0], vid2.loc[0].values])\n",
    "        test_label.append([mat_file['Segment3'][0], vid3.loc[0].values])\n",
    "        test_label.append([mat_file['Segment4'][0], vid4.loc[0].values])\n",
    "        test_label.append([mat_file['Segment5'][0], vid5.loc[0].values])\n",
    "        test_label.append([mat_file['Segment6'][0], vid6.loc[0].values])\n",
    "\n",
    "#x = mat_file['Segment1'].reshape(1, -1)\n",
    "print(train_label[0])\n",
    "print(test_label[0])\n",
    "#len(mat_file['Segment1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d3f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a71b7fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178490,)\n",
      "(193736,)\n",
      "(191559,)\n",
      "(159628,)\n",
      "(226382,)\n",
      "(214049,)\n",
      "(248543,)\n",
      "(298048,)\n",
      "(269761,)\n",
      "(315226,)\n",
      "(292998,)\n",
      "(260666,)\n",
      "(140709,)\n",
      "(170159,)\n",
      "(158161,)\n",
      "(134164,)\n",
      "(145618,)\n",
      "(160889,)\n",
      "(134351,)\n",
      "(161111,)\n",
      "(158381,)\n",
      "(144727,)\n",
      "(141451,)\n",
      "(170396,)\n",
      "(172779,)\n",
      "(208135,)\n",
      "(193459,)\n",
      "(164107,)\n",
      "(196794,)\n",
      "(176780,)\n",
      "(133879,)\n",
      "(149905,)\n",
      "(152488,)\n",
      "(127160,)\n",
      "(161277,)\n",
      "(136982,)\n",
      "(188084,)\n",
      "(159751,)\n",
      "(156134,)\n",
      "(177836,)\n",
      "(174822,)\n",
      "(148297,)\n",
      "(206909,)\n",
      "(172541,)\n",
      "(181659,)\n",
      "(203402,)\n",
      "(185867,)\n",
      "(218833,)\n",
      "(193425,)\n",
      "(152510,)\n",
      "(182887,)\n",
      "(160569,)\n",
      "(179787,)\n",
      "(164289,)\n",
      "(194011,)\n",
      "(169678,)\n",
      "(161786,)\n",
      "(175598,)\n",
      "(190724,)\n",
      "(205193,)\n",
      "(177450,)\n",
      "(194191,)\n",
      "(164728,)\n",
      "(208924,)\n",
      "(173434,)\n",
      "(197540,)\n",
      "(160676,)\n",
      "(142946,)\n",
      "(136297,)\n",
      "(172865,)\n",
      "(147932,)\n",
      "(163445,)\n",
      "(135853,)\n",
      "(152703,)\n",
      "(140593,)\n",
      "(164288,)\n",
      "(129535,)\n",
      "(155336,)\n",
      "(67616,)\n",
      "(73388,)\n",
      "(81084,)\n",
      "(85757,)\n",
      "(79709,)\n",
      "(70914,)\n",
      "(178702,)\n",
      "(189001,)\n",
      "(175674,)\n",
      "(156895,)\n",
      "(160530,)\n",
      "(149020,)\n",
      "(254153,)\n",
      "(242331,)\n",
      "(263018,)\n",
      "(290600,)\n",
      "(285675,)\n",
      "(307347,)\n",
      "(202610,)\n",
      "(217980,)\n",
      "(186541,)\n",
      "(206102,)\n",
      "(180252,)\n",
      "(171868,)\n",
      "(323243,)\n",
      "(254865,)\n",
      "(276623,)\n",
      "(300452,)\n",
      "(267298,)\n",
      "(305632,)\n",
      "(180752,)\n",
      "(168007,)\n",
      "(142516,)\n",
      "(149468,)\n",
      "(154682,)\n",
      "(170904,)\n",
      "(165914,)\n",
      "(156874,)\n",
      "(154216,)\n",
      "(137198,)\n",
      "(141985,)\n",
      "(130817,)\n",
      "(202500,)\n",
      "(159664,)\n",
      "(168102,)\n",
      "(188222,)\n",
      "(191467,)\n",
      "(171996,)\n",
      "(191499,)\n",
      "(188253,)\n",
      "(159691,)\n",
      "(202534,)\n",
      "(173322,)\n",
      "(167481,)\n",
      "(148566,)\n",
      "(126025,)\n",
      "(151127,)\n",
      "(132684,)\n",
      "(135758,)\n",
      "(159837,)\n",
      "(165791,)\n",
      "(130721,)\n",
      "(156757,)\n",
      "(154101,)\n",
      "(140817,)\n",
      "(137628,)\n",
      "(143625,)\n",
      "(169314,)\n",
      "(155886,)\n",
      "(182159,)\n",
      "(150631,)\n",
      "(172233,)\n",
      "(155786,)\n",
      "(173421,)\n",
      "(152258,)\n",
      "(144616,)\n",
      "(183417,)\n",
      "(170482,)\n",
      "(131991,)\n",
      "(167403,)\n",
      "(155600,)\n",
      "(138430,)\n",
      "(143258,)\n",
      "(158282,)\n",
      "(156152,)\n",
      "(177855,)\n",
      "(159769,)\n",
      "(188105,)\n",
      "(148314,)\n",
      "(174842,)\n",
      "(151594,)\n",
      "(154208,)\n",
      "(128593,)\n",
      "(138525,)\n",
      "(163094,)\n",
      "(135388,)\n",
      "(187306,)\n",
      "(177099,)\n",
      "(174098,)\n",
      "(159090,)\n",
      "(147683,)\n",
      "(155487,)\n",
      "(204982,)\n",
      "(169504,)\n",
      "(190528,)\n",
      "(161620,)\n",
      "(175416,)\n",
      "(193813,)\n",
      "(155438,)\n",
      "(164396,)\n",
      "(135942,)\n",
      "(140685,)\n",
      "(152804,)\n",
      "(129620,)\n",
      "(168376,)\n",
      "(159202,)\n",
      "(143012,)\n",
      "(156504,)\n",
      "(139774,)\n",
      "(132759,)\n",
      "(129846,)\n",
      "(139874,)\n",
      "(164682,)\n",
      "(136707,)\n",
      "(153070,)\n",
      "(155709,)\n",
      "(164562,)\n",
      "(136608,)\n",
      "(155595,)\n",
      "(152958,)\n",
      "(129751,)\n",
      "(139772,)\n",
      "(188943,)\n",
      "(156241,)\n",
      "(175620,)\n",
      "(148974,)\n",
      "(161692,)\n",
      "(178648,)\n",
      "(290032,)\n",
      "(320448,)\n",
      "(267222,)\n",
      "(309114,)\n",
      "(338915,)\n",
      "(280257,)\n",
      "(173901,)\n",
      "(158909,)\n",
      "(176899,)\n",
      "(147516,)\n",
      "(155311,)\n",
      "(187094,)\n",
      "(202670,)\n",
      "(188380,)\n",
      "(172139,)\n",
      "(168243,)\n",
      "(159797,)\n",
      "(191628,)\n",
      "(158766,)\n",
      "(181536,)\n",
      "(191997,)\n",
      "(178458,)\n",
      "(151382,)\n",
      "(164305,)\n",
      "(145880,)\n",
      "(163878,)\n",
      "(181063,)\n",
      "(177994,)\n",
      "(191498,)\n",
      "(158354,)\n",
      "(285106,)\n",
      "(258045,)\n",
      "(237750,)\n",
      "(301537,)\n",
      "(280274,)\n",
      "(249346,)\n",
      "(172727,)\n",
      "(136188,)\n",
      "(163316,)\n",
      "(160548,)\n",
      "(147815,)\n",
      "(142832,)\n",
      "(181343,)\n",
      "(196965,)\n",
      "(211908,)\n",
      "(175231,)\n",
      "(167081,)\n",
      "(200361,)\n",
      "(253954,)\n",
      "(233979,)\n",
      "(245393,)\n",
      "(280585,)\n",
      "(275829,)\n",
      "(296755,)\n",
      "(159708,)\n",
      "(139677,)\n",
      "(157000,)\n",
      "(144549,)\n",
      "(133180,)\n",
      "(168911,)\n",
      "(159952,)\n",
      "(143686,)\n",
      "(133383,)\n",
      "(169169,)\n",
      "(157241,)\n",
      "(140432,)\n",
      "(324760,)\n",
      "(268552,)\n",
      "(307066,)\n",
      "(256062,)\n",
      "(277920,)\n",
      "(301863,)\n",
      "(134582,)\n",
      "(162750,)\n",
      "(151274,)\n",
      "(128323,)\n",
      "(139277,)\n",
      "(153882,)\n",
      "(158662,)\n",
      "(142527,)\n",
      "(155974,)\n",
      "(167805,)\n",
      "(139301,)\n",
      "(132309,)\n",
      "(145748,)\n",
      "(162249,)\n",
      "(135299,)\n",
      "(142448,)\n",
      "(159498,)\n",
      "(171598,)\n",
      "(129525,)\n",
      "(139529,)\n",
      "(164276,)\n",
      "(152693,)\n",
      "(155325,)\n",
      "(136370,)\n",
      "(154021,)\n",
      "(151411,)\n",
      "(134703,)\n",
      "(162896,)\n",
      "(128438,)\n",
      "(139402,)\n",
      "(139981,)\n",
      "(128972,)\n",
      "(135263,)\n",
      "(163574,)\n",
      "(152039,)\n",
      "(154661,)\n",
      "(262360,)\n",
      "(222552,)\n",
      "(266882,)\n",
      "(241551,)\n",
      "(233409,)\n",
      "(282263,)\n",
      "(204105,)\n",
      "(197226,)\n",
      "(221687,)\n",
      "(188053,)\n",
      "(225511,)\n",
      "(238505,)\n",
      "(134469,)\n",
      "(174909,)\n",
      "(145197,)\n",
      "(162575,)\n",
      "(148561,)\n",
      "(165378,)\n",
      "(155240,)\n",
      "(196889,)\n",
      "(186161,)\n",
      "(162812,)\n",
      "(183006,)\n",
      "(168492,)\n",
      "(152977,)\n",
      "(183448,)\n",
      "(194019,)\n",
      "(164791,)\n",
      "(180337,)\n",
      "(161060,)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for xt in train_label :\n",
    "    print(xt[0].shape)#.reshape(-1).shape)\n",
    "    x_train.append(xt[0])#tf.convert_to_tensor(xt[0]))\n",
    "    y_train.append(xt[1])#tf.convert_to_tensor(xt[1]))\n",
    "    \n",
    "for xt in test_label :\n",
    "    print(xt[0].shape)#.reshape(-1).shape)\n",
    "    x_test.append(xt[0])#tf.convert_to_tensor(xt[0]))\n",
    "    y_test.append(xt[1])#tf.convert_to_tensor(xt[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a44f6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 1, 1, 5, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train[0])\n",
    "#print(type(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "412eecb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 338915)\n",
      "[[507. 503. 503. ...   0.   0.   0.]\n",
      " [535. 551. 571. ...   0.   0.   0.]\n",
      " [500. 500. 498. ...   0.   0.   0.]\n",
      " ...\n",
      " [593. 606. 612. ...   0.   0.   0.]\n",
      " [469. 469. 471. ...   0.   0.   0.]\n",
      " [487. 483. 482. ...   0.   0.   0.]]\n",
      "(108, 338915)\n",
      "[[445. 444. 446. ...   0.   0.   0.]\n",
      " [485. 483. 482. ...   0.   0.   0.]\n",
      " [444. 442. 441. ...   0.   0.   0.]\n",
      " ...\n",
      " [498. 501. 499. ...   0.   0.   0.]\n",
      " [486. 488. 488. ...   0.   0.   0.]\n",
      " [494. 495. 494. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 338915\n",
    "padded_data = np.zeros((len(x_train), max_length))\n",
    "\n",
    "for i, d in enumerate(x_train):\n",
    "    padded_data[i, :len(d)] = d\n",
    "\n",
    "print(padded_data.shape)\n",
    "x_train = padded_data\n",
    "print(x_train)\n",
    "\n",
    "padded_data = np.zeros((len(x_test), max_length))\n",
    "\n",
    "for i, d in enumerate(x_test):\n",
    "    padded_data[i, :len(d)] = d\n",
    "\n",
    "print(padded_data.shape)\n",
    "x_test = padded_data\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f621616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 338915)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97162ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(y_train) :\n",
    "    #print(i)\n",
    "    y_train[i] =  np.array(idx)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for i, idx in enumerate(y_test) :\n",
    "    #print(i)\n",
    "    y_test[i] =  np.array(idx)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ae1d7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.random.rand(100, 100, 1)\n",
    "num_samples = input_data.shape[0]\n",
    "num_samples\n",
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40e357d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(max_length, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "batch_size = 1\n",
    "num_samples = 246\n",
    "features = []\n",
    "\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    batch = x_train[i:i+batch_size]\n",
    "    extracted_features = model.predict(batch)\n",
    "    features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "160a5dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n",
      "[0.4375 0.0625 0.0625 0.3125 0.0625 0.0625]\n",
      "[0.0625 0.3125 0.0625 0.0625 0.0625 0.4375]\n",
      "[0.09090909 0.54545455 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.22222222 0.11111111 0.33333333 0.11111111 0.11111111 0.11111111]\n",
      "[0.16666667 0.08333333 0.08333333 0.5        0.08333333 0.08333333]\n",
      "[0.07692308 0.07692308 0.07692308 0.07692308 0.46153846 0.23076923]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_train)) :\n",
    "    print(y_train[i]/sum(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb8dce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 6) and (None, 64) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#,\u001b[39;00m\n\u001b[0;32m     15\u001b[0m               \u001b[38;5;66;03m#metrics=['accuracy'])\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#model.add(Flatten())\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filei71qk8aw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\82108\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 6) and (None, 64) are incompatible\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(max_length, 1)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='softmax')\n",
    "])\"\"\"\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy')#,\n",
    "              #metrics=['accuracy'])\n",
    "#model.add(Flatten())\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c6d73c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 338913, 32)        128       \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 169456, 32)       0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 169454, 64)        6208      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 84727, 64)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 84725, 128)        24704     \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 128)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,296\n",
      "Trainable params: 39,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49c62761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step\n"
     ]
    }
   ],
   "source": [
    "cnnoutput = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76518e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
